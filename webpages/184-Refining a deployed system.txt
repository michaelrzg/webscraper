




Refining a deployed system
























 Next: Results snippets
 Up: A broader perspective: System
 Previous: User utility
    Contents 
    Index




Refining a deployed system


If an IR system has been built and is being used by a large number
of users, the system's builders can evaluate possible changes by deploying variant versions of the system and recording measures that are indicative of
user satisfaction with one variant vs. others as they are
being used.  This method is frequently used by 
web search engines.


The most common version of this is  A/B testing , a term borrowed from the advertising industry.  For such a test, precisely one thing is changed between the current system and a proposed system, and a small proportion of traffic (say, 1-10% of users) is randomly directed to the
variant system, while most users use the current system.
For example, if we wish to investigate a change to the ranking
algorithm, we redirect a random sample of users to a variant system and evaluate measures such as the frequency with which
people click on the top result, or any result on the first page.
(This particular analysis method is referred to as  clickthrough log analysis  or
 clickstream mining .  It is further discussed as a method of
implicit feedback in Section 9.1.7 (page ).)


The basis of A/B testing is running a bunch of single
variable tests (either in sequence or in parallel): for each
test only one parameter is varied from the control (the
current live system). It is therefore easy to see whether
varying each parameter has a positive or negative effect.
Such testing of a live system can easily and cheaply gauge
the effect of a change on users, and, with a large enough
user base, it is practical to measure even very small
positive and negative effects. In principle, more analytic
power can be achieved by varying multiple things at once in
an uncorrelated (random) way, and doing standard
multivariate statistical analysis, such as multiple linear
regression.  


In
practice, though, A/B testing is widely used, because A/B
tests are easy to deploy, easy to understand, and easy to
explain to management.















 Next: Results snippets
 Up: A broader perspective: System
 Previous: User utility
    Contents 
    Index


© 2008 Cambridge University PressThis is an automatically generated page. In case of formatting errors you may want to look at the PDF edition of the book.
2009-04-07



